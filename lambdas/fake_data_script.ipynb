{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages\n",
    "import boto3\n",
    "import pprint\n",
    "from boto3.dynamodb.conditions import Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up connection with dynamoDB\n",
    "region_name = 'us-east-1'\n",
    "dynamodb = boto3.resource('dynamodb', region_name=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'app': 'asfpsfafas', 'num_devices': Decimal('600'), 'attributeTypes': ['N', 'N'], 'attributeRangeMaxes': ['1000', '12'], 'logo_image_url': 'bingus', 'attributeRangeMins': ['600', '4'], 'placeholder': 'placeholder', 'category': 'Consumer', 'dataset_id': 'henlo', 'attributes': ['wapapa', 'wowowow'], 'name': 'bingus'}\n"
     ]
    }
   ],
   "source": [
    "# function used to ensure I understood how to make calls to dynamo\n",
    "def get_table_stuff(table1):\n",
    "    \n",
    "    response = table1.get_item(Key={'dataset_id': 'henlo'})\n",
    "    \n",
    "    return response['Item']\n",
    "\n",
    "abc = get_table_stuff(table)\n",
    "print (abc)"
   ]
  },
  {
   "source": [
    "#### Simply building a fake dataset off of one example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will only ever make a fake dataset from dataset table, so may as well declare it!\n",
    "table = dynamodb.Table('dataset_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\"'0'\", \"'1'\"]\n"
     ]
    }
   ],
   "source": [
    "# more testing - this takes in a dataset id, converts it into a dictionary\n",
    "\n",
    "def preprocess_dynamo_row(column_header, input):\n",
    "\n",
    "    response = table.get_item(Key={column_header: input})\n",
    "    return response['Item']\n",
    "\n",
    "abc = (preprocess_dynamo_row('dataset_id', 'tobytest'))\n",
    "dict = abc['Correlation']\n",
    "print (list(dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(['wapapa', 'wowowow'], ['N', 'N'], 600, [[600.0, 1000.0], [4.0, 12.0]])\n"
     ]
    }
   ],
   "source": [
    "# this function will grab the relevant rows (column header, min, max, num_rows)\n",
    "def grab_relevant_info(column_header, input):\n",
    "\n",
    "    # this grabs the dictionary of the row of data we want!\n",
    "    dict = preprocess_dynamo_row(column_header, input)\n",
    "\n",
    "    columns = []\n",
    "    schema = []\n",
    "    num_rows = 0\n",
    "    ranges = []\n",
    "    #correlation = []\n",
    "\n",
    "    # grab the column headers; we assume that this is the right length of columns the data should be.\n",
    "    columns = dict['attributes']\n",
    "\n",
    "    # grab the data schema, we assume that this is per row (i.e. if 3 columns of data, this is the same length)\n",
    "    schema = dict['attributeTypes']\n",
    "\n",
    "    # grab the number of rows (fake data)\n",
    "    num_rows = int(dict['num_devices']) # this avoids any problem with that it is a Decimal value\n",
    "\n",
    "    \n",
    "    # to create ranges we need to make sure our data is not all string and/or binary\n",
    "    num = 0 # we assume it IS all string/binary, the schema must prove us wrong\n",
    "    for i in range(len(schema)):\n",
    "        if schema[i] == \"N\":\n",
    "            num = 1\n",
    "    \n",
    "    # this makes sure there is one number, i.e. there has to be a range!       \n",
    "    # if the bool is false there is no 'attributerange...' hence we need to instantiate a list somehow\n",
    "    if (num == 1):\n",
    "        mins = dict['attributeRangeMins']\n",
    "        maxs = dict['attributeRangeMaxes']\n",
    "    else:\n",
    "        mins = []\n",
    "        maxs = []\n",
    "    \n",
    "    # corresponding min and max of column; if string, make [0, 0]\n",
    "    min_max_counter = 0 # this tracks the smaller array\n",
    "\n",
    "    # go through each column and figure out if its range exists OR we must add a value\n",
    "    # suppose schema = [S, N, S], then range only equals [[3, 10]], must append [0, 0] for index 0 and 2 so we can iterate cleanly in other functions\n",
    "    for i in range(len(columns)):\n",
    "        if schema[i] == 'S':\n",
    "            ranges.append([])\n",
    "            ranges[i].append([0, 0])\n",
    "        elif schema[i] == 'B':\n",
    "            ranges.append([[]])\n",
    "            ranges[i].append([0, 1])\n",
    "        else:\n",
    "            ranges.append([])\n",
    "            ranges[i].append(float(mins[min_max_counter]))\n",
    "            ranges[i].append(float(maxs[min_max_counter]))\n",
    "            min_max_counter += 1\n",
    "    \n",
    "    # find correlation; this will be later. this supposes that we have another column of length n where 0 = no correlation with anyone else\n",
    "    # a non-zero means that this column is a function of another column (so each non-zero must occur at least twice!)\n",
    "    # a function of the other column goes both ways which enables flexibility in terms of how we write the code (refer to my last PR in correlated_fake_data in our experimental repo)\n",
    "    # correlation = list(dict['Correlation'])\n",
    "\n",
    "    return columns, schema, num_rows, ranges #,correlation\n",
    "\n",
    "test_data = grab_relevant_info('dataset_id', 'henlo')\n",
    "print (test_data)\n",
    "test_columns = test_data[0]\n",
    "test_schema = test_data[1]\n",
    "test_num_rows = test_data[2]\n",
    "test_ranges = test_data[3]\n",
    "# test_correlation = test_data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[0, 0]], [[0, 0]], [3.0, 4.0], [[0, 1]]]\n"
     ]
    }
   ],
   "source": [
    "# test function to confirm the logic works; shows how we can append ranges\n",
    "schema = ['S', 'S', 'N', 'B']\n",
    "mins = [3]\n",
    "maxs = [4]\n",
    "def test(schema, mins, maxs):\n",
    "    ranges = []\n",
    "    min_max_counter = 0 # this tracks the smaller array\n",
    "    # hard to test this given the DynamoDB oddity of data, so this is just a manual test\n",
    "    for i in range(len(schema)):\n",
    "        if schema[i] == 'S':\n",
    "            ranges.append([])\n",
    "            ranges[i].append([0, 0])\n",
    "        elif schema[i] == 'B':\n",
    "            ranges.append([])\n",
    "            ranges[i].append([0, 1])\n",
    "        else:\n",
    "            ranges.append([])\n",
    "            ranges[i].append(float(mins[min_max_counter]))\n",
    "            ranges[i].append(float(maxs[min_max_counter]))\n",
    "            min_max_counter += 1\n",
    "            \n",
    "    return ranges\n",
    "print (test(schema, mins, maxs))"
   ]
  },
  {
   "source": [
    "#### The below function takes in column, range, and the number of rows and produces randomized integers in the range of each column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['the', 'of', 'and', 'to', 'a', 'in', 'for', 'is', 'on', 'that', 'by', 'this', 'with', 'i', 'you', 'it', 'not', 'or', 'be', 'are', 'from', 'at', 'as', 'your', 'all', 'have', 'new', 'more', 'an', 'was', 'we', 'will', 'home', 'can', 'us', 'about', 'if', 'page', 'my', 'has', 'search', 'free', 'but', 'our', 'one', 'other', 'do', 'no', 'information', 'time', 'they', 'site', 'he', 'up', 'may', 'what', 'which', 'their', 'news', 'out', 'use', 'any', 'there', 'see', 'only', 'so', 'his', 'when', 'contact', 'here', 'business', 'who', 'web', 'also', 'now', 'help', 'get', 'pm', 'view', 'online', 'c', 'e', 'first', 'am', 'been', 'would', 'how', 'were', 'me', 's', 'services', 'some', 'these', 'click', 'its', 'like', 'service', 'x', 'than', 'find', 'price', 'date', 'back', 'top', 'people', 'had', 'list', 'name', 'just', 'over', 'state', 'year', 'day', 'into', 'email', 'two', 'health', 'n', 'world', 're', 'next', 'used', 'go', 'b', 'work', 'last', 'most', 'products', 'music', 'buy', 'data', 'make', 'them', 'should', 'product', 'system', 'post', 'her', 'city', 't', 'add', 'policy', 'number', 'such', 'please', 'available', 'copyright', 'support', 'message', 'after', 'best', 'software', 'then', 'jan', 'good', 'video', 'well', 'd', 'where', 'info', 'rights', 'public', 'books', 'high', 'school', 'through', 'm', 'each', 'links', 'she', 'review', 'years', 'order', 'very', 'privacy', 'book', 'items', 'company', 'r', 'read', 'group', 'sex', 'need', 'many', 'user', 'said', 'de', 'does', 'set', 'under', 'general', 'research', 'university', 'january', 'mail', 'full', 'map', 'reviews', 'program', 'life', 'know', 'games', 'way', 'days', 'management', 'p', 'part', 'could', 'great', 'united', 'hotel', 'real', 'f', 'item', 'international', 'center', 'ebay', 'must', 'store', 'travel', 'comments', 'made', 'development', 'report', 'off', 'member', 'details', 'line', 'terms', 'before', 'hotels', 'did', 'send', 'right', 'type', 'because', 'local', 'those', 'using', 'results', 'office', 'education', 'national', 'car', 'design', 'take', 'posted', 'internet', 'address', 'community', 'within', 'states', 'area', 'want', 'phone', 'dvd', 'shipping', 'reserved', 'subject', 'between', 'forum', 'family', 'l', 'long', 'based', 'w', 'code', 'show', 'o', 'even', 'black', 'check', 'special', 'prices', 'website', 'index', 'being', 'women', 'much', 'sign', 'file', 'link', 'open', 'today', 'technology', 'south', 'case', 'project', 'same', 'pages', 'uk', 'version', 'section', 'own', 'found', 'sports', 'house', 'related', 'security', 'both', 'g', 'county', 'american', 'photo', 'game', 'members', 'power', 'while', 'care', 'network', 'down', 'computer', 'systems', 'three', 'total', 'place', 'end', 'following', 'download', 'h', 'him', 'without', 'per', 'access', 'think', 'north', 'resources', 'current', 'posts', 'big', 'media', 'law', 'control', 'water', 'history', 'pictures', 'size', 'art', 'personal', 'since', 'including', 'guide', 'shop', 'directory', 'board', 'location', 'change', 'white', 'text', 'small', 'rating', 'rate', 'government', 'children', 'during', 'usa', 'return', 'students', 'v', 'shopping', 'account', 'times', 'sites', 'level', 'digital', 'profile', 'previous', 'form', 'events', 'love', 'old', 'john', 'main', 'call', 'hours', 'image', 'department', 'title', 'description', 'non', 'k', 'y', 'insurance', 'another', 'why', 'shall', 'property', 'class', 'cd', 'still', 'money', 'quality', 'every', 'listing', 'content', 'country', 'private', 'little', 'visit', 'save', 'tools', 'low', 'reply', 'customer', 'december', 'compare', 'movies', 'include', 'college', 'value', 'article', 'york', 'man', 'card', 'jobs', 'provide', 'j', 'food', 'source', 'author', 'different', 'press', 'u', 'learn', 'sale', 'around', 'print', 'course', 'job', 'canada', 'process', 'teen', 'room', 'stock', 'training', 'too', 'credit', 'point', 'join', 'science', 'men', 'categories', 'advanced', 'west', 'sales', 'look', 'english', 'left', 'team', 'estate', 'box', 'conditions', 'select', 'windows', 'photos', 'gay', 'thread', 'week', 'category', 'note', 'live', 'large', 'gallery', 'table', 'register', 'however', 'june', 'october', 'november', 'market', 'library', 'really', 'action', 'start', 'series', 'model', 'features', 'air', 'industry', 'plan', 'human', 'provided', 'tv', 'yes', 'required', 'second', 'hot', 'accessories', 'cost', 'movie', 'forums', 'march', 'la', 'september', 'better', 'say', 'questions', 'july', 'yahoo', 'going', 'medical', 'test', 'friend', 'come', 'dec', 'server', 'pc', 'study', 'application', 'cart', 'staff', 'articles', 'san', 'feedback', 'again', 'play', 'looking', 'issues', 'april', 'never', 'users', 'complete', 'street', 'topic', 'comment', 'financial', 'things', 'working', 'against', 'standard', 'tax', 'person', 'below', 'mobile', 'less', 'got', 'blog', 'party', 'payment', 'equipment', 'login', 'student', 'let', 'programs', 'offers', 'legal', 'above', 'recent', 'park', 'stores', 'side', 'act', 'problem', 'red', 'give', 'memory', 'performance', 'social', 'q', 'august', 'quote', 'language', 'story', 'sell', 'options', 'experience', 'rates', 'create', 'key', 'body', 'young', 'america', 'important', 'field', 'few', 'east', 'paper', 'single', 'ii', 'age', 'activities', 'club', 'example', 'girls', 'additional', 'password', 'z', 'latest', 'something', 'road', 'gift', 'question', 'changes', 'night', 'ca', 'hard', 'texas', 'oct', 'pay', 'four', 'poker', 'status', 'browse', 'issue', 'range', 'building', 'seller', 'court', 'february', 'always', 'result', 'audio', 'light', 'write', 'war', 'nov', 'offer', 'blue', 'groups', 'al', 'easy', 'given', 'files', 'event', 'release', 'analysis', 'request', 'fax', 'china', 'making', 'picture', 'needs', 'possible', 'might', 'professional', 'yet', 'month', 'major', 'star', 'areas', 'future', 'space', 'committee', 'hand', 'sun', 'cards', 'problems', 'london', 'washington', 'meeting', 'rss', 'become', 'interest', 'id', 'child', 'keep', 'enter', 'california', 'porn', 'share', 'similar', 'garden', 'schools', 'million', 'added', 'reference', 'companies', 'listed', 'baby', 'learning', 'energy', 'run', 'delivery', 'net', 'popular', 'term', 'film', 'stories', 'put', 'computers', 'journal', 'reports', 'co', 'try', 'welcome', 'central', 'images', 'president', 'notice', 'god', 'original', 'head', 'radio', 'until', 'cell', 'color', 'self', 'council', 'away', 'includes', 'track', 'australia', 'discussion', 'archive', 'once', 'others', 'entertainment', 'agreement', 'format', 'least', 'society', 'months', 'log', 'safety', 'friends', 'sure', 'faq', 'trade', 'edition', 'cars', 'messages', 'marketing', 'tell', 'further', 'updated', 'association', 'able', 'having', 'provides', 'david', 'fun', 'already', 'green', 'studies', 'close', 'common', 'drive', 'specific', 'several', 'gold', 'feb', 'living', 'sep', 'collection', 'called', 'short', 'arts', 'lot', 'ask', 'display', 'limited', 'powered', 'solutions', 'means', 'director', 'daily', 'beach', 'past', 'natural', 'whether', 'due', 'et', 'electronics', 'five', 'upon', 'period', 'planning', 'database', 'says', 'official', 'weather', 'mar', 'land', 'average', 'done', 'technical', 'window', 'france', 'pro', 'region', 'island', 'record', 'direct', 'microsoft', 'conference', 'environment', 'records', 'st', 'district', 'calendar', 'costs', 'style', 'url', 'front', 'statement', 'update', 'parts', 'aug', 'ever', 'downloads', 'early', 'miles', 'sound', 'resource', 'present', 'applications', 'either', 'ago', 'document', 'word', 'works', 'material', 'bill', 'apr', 'written', 'talk', 'federal', 'hosting', 'rules', 'final', 'adult', 'tickets', 'thing', 'centre', 'requirements', 'via', 'cheap', 'nude', 'kids', 'finance', 'true', 'minutes', 'else', 'mark', 'third', 'rock', 'gifts', 'europe', 'reading', 'topics', 'bad', 'individual', 'tips', 'plus', 'auto', 'cover', 'usually', 'edit', 'together', 'videos', 'percent', 'fast', 'function', 'fact', 'unit', 'getting', 'global', 'tech', 'meet', 'far', 'economic', 'en', 'player', 'projects', 'lyrics', 'often', 'subscribe', 'submit', 'germany', 'amount', 'watch', 'included', 'feel', 'though', 'bank', 'risk', 'thanks', 'everything', 'deals', 'various', 'words', 'linux', 'jul', 'production', 'commercial', 'james', 'weight', 'town', 'heart', 'advertising', 'received', 'choose', 'treatment', 'newsletter', 'archives', 'points', 'knowledge', 'magazine', 'error', 'camera', 'jun', 'girl', 'currently', 'construction', 'toys', 'registered', 'clear', 'golf', 'receive', 'domain', 'methods', 'chapter', 'makes', 'protection', 'policies', 'loan', 'wide', 'beauty', 'manager', 'india', 'position', 'taken', 'sort', 'listings', 'models', 'michael', 'known', 'half', 'cases', 'step', 'engineering', 'florida', 'simple', 'quick', 'none', 'wireless', 'license', 'paul', 'friday', 'lake', 'whole', 'annual', 'published', 'later', 'basic', 'sony', 'shows', 'corporate', 'google', 'church', 'method', 'purchase', 'customers', 'active', 'response', 'practice', 'hardware', 'figure', 'materials', 'fire', 'holiday', 'chat', 'enough', 'designed', 'along', 'among', 'death', 'writing', 'speed', 'html', 'countries', 'loss', 'face', 'brand', 'discount', 'higher', 'effects', 'created', 'remember', 'standards', 'oil', 'bit', 'yellow', 'political', 'increase', 'advertise', 'kingdom', 'base', 'near', 'environmental', 'thought', 'stuff', 'french', 'storage', 'oh', 'japan', 'doing', 'loans', 'shoes', 'entry']\nmany\n"
     ]
    }
   ],
   "source": [
    "# this figures out the words.txt (taken from https://github.com/first20hours/google-10000-english/blob/master/20k.txt) \n",
    "# I took the 1k most popular words)\n",
    "f = open('words.txt', 'r')\n",
    "content = f.read()\n",
    "word_list = str.split(content)\n",
    "print (word_list)\n",
    "print (word_list[random.randint(0, len(word_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['a', 'b', 'c', 'd'], ['being', 8397, 1, 6], ['early', 23334, 0, 6]]"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "# inputs: columns, discrete/continuous, ranges for each column, correlation, number of rows\n",
    "# this has every column besides the first column be a function of the first column\n",
    "# correlation: index of length n, 0 means no correlation with anything else, any non-zero int needs to have a pair (should be validated, will not be yet)\n",
    "# assume earlier index is the one the later one is based on... doesn't really matter\n",
    "def schematic_fake_data(columns, schema, ranges, num_rows):\n",
    "    \n",
    "    # input validation\n",
    "    if not (len(columns) == len(ranges)):\n",
    "        return (\"incorrect lengths of columns in one of the first three inputs\")\n",
    "    elif (num_rows <= 0):\n",
    "        return (\"incorrect number of rows\")\n",
    "\n",
    "    # # this is a dictionary on that tracks the counts of each value in array\n",
    "    # correlation_counter_dict = {}\n",
    "    # validation_counter = 0\n",
    "\n",
    "    # while validation_counter < len(correlation):\n",
    "    #     if correlation[validation_counter] in correlation_counter_dict.keys():\n",
    "    #         correlation_counter_dict[correlation[validation_counter]] += 1\n",
    "    #     else:\n",
    "    #         correlation_counter_dict[correlation[validation_counter]] = 1\n",
    "\n",
    "    #     validation_counter += 1\n",
    "    # val_list = (list(correlation_counter_dict.values()))\n",
    "    # key_list = (list(correlation_counter_dict.keys()))\n",
    "    # for i in val_list:\n",
    "    #     if i < 2:\n",
    "    #         if key_list[val_list.index(i)] != 0:\n",
    "    #             return (\"error: need a corresponding value with this correlation value\")\n",
    "    \n",
    "    output_data = [columns]\n",
    "\n",
    "    col_iterator = 0\n",
    "    row_of_data = 1 # topline is the headers\n",
    "    # write an array where each item is a row of fake data\n",
    "\n",
    "    while row_of_data <= num_rows:\n",
    "\n",
    "        output_data.append([])\n",
    "\n",
    "        while (len(columns) > col_iterator):\n",
    "\n",
    "            # # if this is a \"correlated column\", need to find other column and make it a function of another  \n",
    "            # if (correlation[col_iterator] != 0):\n",
    "                \n",
    "            #     # this finds if this current column is later\n",
    "            #     temp = 0\n",
    "            #     while temp < col_iterator:\n",
    "\n",
    "            #         # this means that this column is later\n",
    "            #         if correlation[temp] == correlation[col_iterator]:\n",
    "            #             output_data[row_of_data].append(output_data[row_of_data][temp] * 3 + random.random() * 5)\n",
    "            #             temp = col_iterator + 2 # to cut out of the loop\n",
    "            #             col_iterator += 1\n",
    "            #         else: \n",
    "            #             temp +=1\n",
    "                \n",
    "            #     # if this column index is earlier, make it random\n",
    "            #     if (schema[col_iterator] == \"int\"):\n",
    "            #         output_data[row_of_data].append(random.randint(range[col_iterator][0], range[col_iterator][1]))\n",
    "            #         col_iterator += 1\n",
    "            #     else:\n",
    "            #         output_data[row_of_data].append(range[col_iterator][0] + random.random() * (range[col_iterator][1] - range[col_iterator][0]))\n",
    "            #         col_iterator += 1\n",
    "\n",
    "            #else: \n",
    "            # if an integer or binary, which means they have an ACTUAL range, we select integer between the two!\n",
    "            if (schema[col_iterator] == \"N\" or schema[col_iterator] == \"B\"):\n",
    "                output_data[row_of_data].append(random.randint(ranges[col_iterator][0], ranges[col_iterator][1]))\n",
    "                col_iterator += 1\n",
    "\n",
    "            # if it a string, we just add a random word from our list of 1k words\n",
    "            elif (schema[col_iterator] == \"S\"):\n",
    "                rand_word = (word_list[random.randint(0, len(word_list) - 1)])\n",
    "                output_data[row_of_data].append(rand_word)\n",
    "                col_iterator += 1\n",
    "\n",
    "            # if not an int, a double, so we get a random double from min to max (i.e. min + (random decimal from 0 --> 1)(max-min))\n",
    "            else:\n",
    "                output_data[row_of_data].append(ranges[col_iterator][0] + random.random() * (ranges[col_iterator][1] - ranges[col_iterator][0]))\n",
    "                col_iterator += 1\n",
    "\n",
    "        col_iterator = 0\n",
    "        row_of_data += 1\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "# test 1 - all kinds, make sure things are outputted correctly\n",
    "schematic_fake_data(['a', 'b', 'c', 'd'], ['S', 'N', 'B', 'N'], [[0, 0], [123, 123123], [0, 1], [5, 7]], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def convert_to_csv(columns, schema, ranges, num_rows, file_name):\n",
    "    output = schematic_fake_data(columns, schema, ranges, num_rows)\n",
    "\n",
    "    with open(file_name, 'w', newline='') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        x = 0\n",
    "        while x < len(output):\n",
    "            spamwriter.writerow(output[x])\n",
    "            x += 1\n",
    "\n",
    "convert_to_csv(test_columns, test_schema, test_ranges, test_num_rows, 'fakedata/no_correlation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_to_csv(column_header, input):\n",
    "    # first, get the dictionary\n",
    "    right_info = grab_relevant_info(column_header, input)\n",
    "    # parse the right info into the four values we need\n",
    "    test_columns = right_info[0]\n",
    "    test_schema = right_info[1]\n",
    "    test_num_rows = right_info[2]\n",
    "    test_ranges = right_info[3]\n",
    "    \n",
    "    # write the csv\n",
    "    filename = ('fakedata/' + input + '.csv')\n",
    "    convert_to_csv(test_columns, test_schema, test_ranges, test_num_rows, filename)\n",
    "\n",
    "query_to_csv('dataset_id', 'henlo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}